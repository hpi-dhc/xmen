{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a3e8444-54ec-41a2-aaef-3849a22cde57",
   "metadata": {},
   "source": [
    "# Combinining NER models with xMEN for German Clinical Entity Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eace0372-6610-4a03-bab6-32e186911bac",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea526a0-3ee4-4a8c-87e2-b5420c33934a",
   "metadata": {},
   "source": [
    "### Get access to GGPONC Models\n",
    "\n",
    "https://www.leitlinienprogramm-onkologie.de/projekte/ggponc-english/\n",
    "\n",
    "and put the spaCy model from the v2.0 release (`models` folder) into a location of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f216b159-7112-473e-a09e-6eff33fa7a34",
   "metadata": {},
   "source": [
    "### Prepare dicts and index\n",
    "\n",
    "`xmen dict conf/ggponc.yaml`\n",
    "\n",
    "`xmen index conf/ggponc.yaml --all --overwrite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e465fea6-7e41-4bc3-abbf-b1c7bf7babbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of spaCy model\n",
    "GGPONC_MODEL_PATH = '../temp/ggponc/spacy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ccc48a-b6fa-4f89-8152-38b336560d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3383e-69f6-4128-8dee-5743d7595ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/hpi-dhc/ggponc_annotation ../temp/ggponc/ggponc_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5793b041-e0c2-4671-bce4-1d957ac35a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "GGPONC_PROJECT_PATH = Path(\"../temp/ggponc/ggponc_annotation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de30f132-1482-4ad7-adf7-4d598852f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(str(GGPONC_PROJECT_PATH / 'spacy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "521b389e-ce31-4e1f-9e37-29986d475a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Florian.Borchert/miniconda3/envs/xmen_notebooks/lib/python3.10/site-packages/spacy/util.py:877: UserWarning: [W095] Model 'de_pipeline' (0.0.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.4.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import snomed_spans # Import custom span suggester and scorer for spaCy spancat \n",
    "\n",
    "nlp = spacy.load(GGPONC_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8049cf19-4a70-4bac-af9a-416c4e7a60e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cetuximab ist ein monoklonaler Antikörper, der gegen den epidermalen Wachstumsfaktorrezeptor (EGFR) gerichtet ist unddient zur Therapie des fortgeschrittenen kolorektalen Karzinoms zusammen mit Irinotecan oder in Kombination mit FOLFOX bzw. allein nach Versagen einer Behandlung mit Oxaliplatin und Irinotecan.',\n",
       " 'Als Alternative empfiehlt die ASCCP bei zytologischem Verdacht auf CIN 1/2 die sofortige Kolposkopie.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Cetuximab ist ein monoklonaler Antikörper, der gegen den epidermalen Wachstumsfaktorrezeptor (EGFR) gerichtet ist und\" \\\n",
    "       \"dient zur Therapie des fortgeschrittenen kolorektalen Karzinoms zusammen mit Irinotecan oder in Kombination mit FOLFOX bzw. \" \\\n",
    "       \"allein nach Versagen einer Behandlung mit Oxaliplatin und Irinotecan.\",\n",
    "    \"Als Alternative empfiehlt die ASCCP bei zytologischem Verdacht auf CIN 1/2 die sofortige Kolposkopie.\"\n",
    "]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5feca36d-cff3-4e02-858e-8d46c0c3d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(nlp.pipe(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2027e23-976c-4e6c-a73b-106565d82749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cetuximab --- Clinical_Drug\n",
      "monoklonaler Antikörper --- Clinical_Drug\n",
      "epidermalen Wachstumsfaktorrezeptor --- Nutrient_or_Body_Substance\n",
      "EGFR --- Nutrient_or_Body_Substance\n",
      "Therapie des fortgeschrittenen kolorektalen Karzinoms --- Therapeutic\n",
      "fortgeschrittenen kolorektalen Karzinoms --- Diagnosis_or_Pathology\n",
      "Irinotecan --- Clinical_Drug\n",
      "FOLFOX --- Therapeutic\n",
      "Versagen --- Diagnosis_or_Pathology\n",
      "Behandlung mit Oxaliplatin und Irinotecan --- Therapeutic\n",
      "Oxaliplatin --- Clinical_Drug\n",
      "Irinotecan --- Clinical_Drug\n",
      "zytologischem Verdacht auf CIN 1/2 --- Other_Finding\n",
      "sofortige Kolposkopie --- Diagnostic\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    for span in sorted(d.spans['snomed'], key=lambda s: s.start):\n",
    "        print(span, '---', span.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae82793-8135-41a2-b6f5-75e39e1e57b1",
   "metadata": {},
   "source": [
    "# Run Entity Linker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b0add5-9fb7-4eb4-9495-91ee5a5c95ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.data import from_spacy\n",
    "from xmen.linkers import SapBERTLinker, TFIDFNGramLinker, EnsembleLinker\n",
    "from xmen.confhelper import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46831d66-e521-4225-9b92-a40d7b7582e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = from_spacy(docs, span_key='snomed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe0976ee-7951-49cf-b582-08489f8b2918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'document_id': 1,\n",
       " 'passages': [{'id': 0,\n",
       "   'offsets': [[0, 101]],\n",
       "   'text': ['Als Alternative empfiehlt die ASCCP bei zytologischem Verdacht auf CIN 1/2 die sofortige Kolposkopie.'],\n",
       "   'type': 'sentence'}],\n",
       " 'entities': [{'id': 0,\n",
       "   'normalized': [],\n",
       "   'offsets': [[40, 74]],\n",
       "   'text': ['zytologischem Verdacht auf CIN 1/2'],\n",
       "   'type': 'Other_Finding'},\n",
       "  {'id': 1,\n",
       "   'normalized': [],\n",
       "   'offsets': [[79, 100]],\n",
       "   'text': ['sofortige Kolposkopie'],\n",
       "   'type': 'Diagnostic'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "286a07dc-e5a3-42af-89f7-b48e035f0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = load_config('../conf/ggponc.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3abe18e-4774-4832-972c-5ad80c305f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_linker = TFIDFNGramLinker(**conf.linker.candidate_generation.ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5748a464-22a5-45fd-b160-bbd25833228c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = ngram_linker.predict_batch(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932a252-1fd0-4f3c-bf7d-ac20095aa440",
   "metadata": {},
   "outputs": [],
   "source": [
    "SapBERTLinker.clear()\n",
    "sap_linker = SapBERTLinker(**conf.linker.candidate_generation.sapbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3689a61-2ee1-4c81-afc7-6f6751654020",
   "metadata": {},
   "source": [
    "## Semantic Type Filtering\n",
    "\n",
    "We filter the generated output to make sure the semantic type of the predicted concepts actually matches the semantic class of the named entity.\n",
    "\n",
    "As the GGPONC entity classes are based on SNOMED CT top level concepts, while we link against UMLS CUIS, we provide a mapping of GGPONC enitity types to UMLS TUIs in `ggponc2tui.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "515adb34-e2de-4f7f-b133-41ddf8ca421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.kb import load_kb\n",
    "from xmen.data import SemanticTypeFilter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29f28a60-d5d4-4ee3-bedb-55e71d15fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = load_kb(Path(conf.cache_dir) / 'ggponc' / 'ggponc.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df540489-bdb6-4e60-a4bf-59860861d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "tui_df = pd.read_csv('ggponc2tui.csv')\n",
    "type2tui = {}\n",
    "for c in ['Diagnosis_or_Pathology',\n",
    "       'Other_Finding', 'Clinical_Drug', 'Nutrient_or_Body_Substance',\n",
    "       'External_Substance', 'Therapeutic', 'Diagnostic']:\n",
    "    type2tui[c] = list(tui_df.TUI[tui_df[c] == 'x'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b7f48f2-9b8d-41f7-a526-49b9ff318170",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_filter = SemanticTypeFilter(type2tui, kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14ebda62-a868-4bc9-8c84-a0580935b0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c66714044cb4d43a57ec091bcabafd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'type_id_to_node'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filtered_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mtype_filter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xmen_notebooks/lib/python3.10/site-packages/xmen/data/semantic_types.py:71\u001b[0m, in \u001b[0;36mSemanticTypeFilter.transform_batch\u001b[0;34m(self, ds)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, ds):\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    Transforms the given dataset by applying the filter_semantic_groups method to each example in the dataset.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    - transformed_ds (tf.data.Dataset): A transformed dataset of examples.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_semantic_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xmen_notebooks/lib/python3.10/site-packages/datasets/arrow_dataset.py:578\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    577\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xmen_notebooks/lib/python3.10/site-packages/datasets/arrow_dataset.py:543\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    541\u001b[0m }\n\u001b[1;32m    542\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xmen_notebooks/lib/python3.10/site-packages/datasets/arrow_dataset.py:3073\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3066\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[1;32m   3067\u001b[0m         disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   3068\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3071\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3072\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3073\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3074\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3075\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/xmen_notebooks/lib/python3.10/site-packages/datasets/arrow_dataset.py:3427\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3425\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3427\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3428\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[1;32m   3429\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/xmen_notebooks/lib/python3.10/site-packages/datasets/arrow_dataset.py:3330\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3329\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3330\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3332\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3333\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3334\u001b[0m     }\n",
      "File \u001b[0;32m~/miniconda3/envs/xmen_notebooks/lib/python3.10/site-packages/xmen/data/semantic_types.py:71\u001b[0m, in \u001b[0;36mSemanticTypeFilter.transform_batch.<locals>.<lambda>\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, ds):\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    Transforms the given dataset by applying the filter_semantic_groups method to each example in the dataset.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    - transformed_ds (tf.data.Dataset): A transformed dataset of examples.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m e: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_semantic_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m, load_from_cache_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/xmen_notebooks/lib/python3.10/site-packages/xmen/data/semantic_types.py:52\u001b[0m, in \u001b[0;36mSemanticTypeFilter.filter_semantic_groups\u001b[0;34m(self, example)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m entities:\n\u001b[1;32m     51\u001b[0m     valid_tuis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_to_tui[e[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m---> 52\u001b[0m     valid_tuis \u001b[38;5;241m=\u001b[39m \u001b[43mexpand_tuis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_tuis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_sem_type_tree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m e[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/xmen_notebooks/lib/python3.10/site-packages/xmen/umls.py:141\u001b[0m, in \u001b[0;36mexpand_tuis\u001b[0;34m(tuis, sem_type_tree)\u001b[0m\n\u001b[1;32m    139\u001b[0m result \u001b[38;5;241m=\u001b[39m tuis\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tuis:\n\u001b[0;32m--> 141\u001b[0m     children \u001b[38;5;241m=\u001b[39m [c\u001b[38;5;241m.\u001b[39mtype_id \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43msem_type_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_id_to_node\u001b[49m[t]\u001b[38;5;241m.\u001b[39mchildren]\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(children) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    143\u001b[0m         result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m children\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'type_id_to_node'"
     ]
    }
   ],
   "source": [
    "filtered_prediction = type_filter.transform_batch(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d26e2c-a9bf-4011-8614-2fa71a1344b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xmen_notebooks]",
   "language": "python",
   "name": "conda-env-xmen_notebooks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
