{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb84db40-b21a-4fba-8174-a327a831ef76",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "Make sure to download the corresponding medical ontologies to build the term dictionaries. For each, look for the 2017 version.\n",
    " - Treatments: [OPS](https://www.bfarm.de/DE/Kodiersysteme/Services/Downloads/_node.html). The required file is `\\p1smt2017\\Klassifikationsdateien\\ops2017syst_kodes.txt` \n",
    " - Medications: [ATC](https://www.wido.de/publikationen-produkte/arzneimittel-klassifikation/). The required file is `ATC GKV AI 2017`\n",
    " - Diagnosis: [ICD10GM](https://www.bfarm.de/DE/Kodiersysteme/Services/Downloads/_node.html). The required file is `\\x1gmt2017\\Klassifikationsdateien\\icd10gm2017syst_kodes.txt`\n",
    " \n",
    "In the config file for BRONCO `../conf/bronco.yaml`, modify the paths so they point the extracted ontologies. We assume they are located in `xmen/temp`. Otherwise, change the path here and correct accordingly the terminal commands below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59201176-35cb-43ad-9c1e-2331e1137608",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065fa6f0-911d-4d9e-924a-faef1646e5d0",
   "metadata": {},
   "source": [
    "We can already use xMEN to prepare the term dictionaries. <u>This step only has to be performed the first time. </u> \n",
    "\n",
    "In your terminal, navigate to the xMEN root folder and run:\n",
    " - `xmen dict conf/bronco.yaml --code dicts/atc2017_de.py --output temp/ --key atc`\n",
    " - `xmen dict conf/bronco.yaml --code dicts/ops2017.py --output temp/ --key ops`\n",
    " - `xmen dict conf/bronco.yaml --code dicts/icd10gm2017.py --output temp/ --key icd10gm`\n",
    " \n",
    "Now use such dictionaries to build the indexes. For this example, we will use only SapBERT indexes and leave aside N-Gram:\n",
    " - `xmen index conf/bronco.yaml --dict temp/atc.jsonl --output temp/atc_index --sapbert`\n",
    " - `xmen index conf/bronco.yaml --dict temp/ops.jsonl --output temp/ops_index --sapbert`\n",
    " - `xmen index conf/bronco.yaml --dict temp/icd10gm.jsonl --output temp/icd10gm_index --sapbert`\n",
    " \n",
    "Now we can load the BRONCO150 dataset using BigBIO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12fbc6ab-f65c-401d-bbe0-99bbcdb2cbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset bronco (/dhc/home/ignacio.rodriguez/.cache/huggingface/datasets/bigbio___bronco/bronco_bigbio_kb-data_dir=..%2F..%2FBRONCO150/1.0.0/cab8fc4a62807688cb5b36df7a24eb7f364314862c4196f6ff2db3813f2fe68b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c001730edb5474292f144ea87af8f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "path_to_data = r\"../../BRONCO150\" # paste here the path to the local data\n",
    "\n",
    "bronco = datasets.load_dataset(path = \"bigbio/bronco\", \n",
    "                               name = \"bronco_bigbio_kb\", \n",
    "                               data_dir=path_to_data)\n",
    "\n",
    "bronco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc91db-df81-4a86-a601-19834659fdc7",
   "metadata": {},
   "source": [
    "Finally, we have to choose the semantic class we want to work on and reestructure the dataset in 5 folds for cross-validation, as originally intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55afb5e6-4324-4ce7-b0ad-9980a6240b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"DIAGNOSIS\" # Choose here TREATMENT, MEDICATION or DIAGNOSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ee0ed32-c4e0-46e5-a89f-03e29b81701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /dhc/home/ignacio.rodriguez/.cache/huggingface/datasets/bigbio___bronco/bronco_bigbio_kb-data_dir=..%2F..%2FBRONCO150/1.0.0/cab8fc4a62807688cb5b36df7a24eb7f364314862c4196f6ff2db3813f2fe68b/cache-a26fddd6429a662a.arrow\n"
     ]
    }
   ],
   "source": [
    "label2dict = {\n",
    "    \"TREATMENT\": \"ops\",\n",
    "    \"MEDICATION\": \"atc\",\n",
    "    \"DIAGNOSIS\": \"icd10gm\"\n",
    "}\n",
    "\n",
    "def filter_entities(bigbio_entities, valid_entities):\n",
    "    filtered_entities = []\n",
    "    for ent in bigbio_entities:\n",
    "        if ent['type'] in valid_entities:\n",
    "            filtered_entities.append(ent)\n",
    "    return filtered_entities\n",
    "\n",
    "ds = bronco.map(lambda row: {'entities': filter_entities(row['entities'], [label])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e8d4826-30d4-4752-83fa-fed2ae359fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    k1: Dataset({\n",
       "        features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "    k2: Dataset({\n",
       "        features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "    k3: Dataset({\n",
       "        features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "    k4: Dataset({\n",
       "        features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "    k5: Dataset({\n",
       "        features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "ground_truth = DatasetDict()\n",
    "for k in range(5):\n",
    "    ground_truth[f\"k{k+1}\"] = ds[\"train\"].select([k])\n",
    "    \n",
    "ds = ground_truth\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec4049-85cb-4a4b-996c-12142d13062a",
   "metadata": {},
   "source": [
    "# Run Candidate Generator\n",
    "We will use `SapBERTLinker`, which uses a Transformer model to retrieve candidates with dense embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11662199-832c-49cf-9591-43eb82e5bc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2\n",
      "For maximum performance, you can install NMSLIB from sources \n",
      "pip install --no-binary :all: nmslib\n"
     ]
    }
   ],
   "source": [
    "from xmen.linkers import SapBERTLinker\n",
    "from xmen.evaluation import evaluate_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fae00e-8bf7-46f1-ba22-875da377db85",
   "metadata": {},
   "source": [
    "<u>This cell can be run just once. For subsequent runs you can load the result with the cell below this one.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12537346-9e8c-4986-8a3b-5f4d068f6294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/30/23 17:24:13] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading hierarchical faiss index                                <a href=\"file:///dhc/home/ignacio.rodriguez/xmen/xmen/linkers/sap_bert_linker.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sap_bert_linker.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///dhc/home/ignacio.rodriguez/xmen/xmen/linkers/sap_bert_linker.py#148\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">148</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/30/23 17:24:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading hierarchical faiss index                                \u001b]8;id=103533;file:///dhc/home/ignacio.rodriguez/xmen/xmen/linkers/sap_bert_linker.py\u001b\\\u001b[2msap_bert_linker.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=795261;file:///dhc/home/ignacio.rodriguez/xmen/xmen/linkers/sap_bert_linker.py#148\u001b\\\u001b[2m148\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading index from                                                 <a href=\"file:///dhc/home/ignacio.rodriguez/xmen/xmen/linkers/faiss_indexer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">faiss_indexer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///dhc/home/ignacio.rodriguez/xmen/xmen/linkers/faiss_indexer.py#64\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">64</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         ..<span style=\"color: #800080; text-decoration-color: #800080\">/temp/icd10gm_index/index/sapbert/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">embed_faiss_hier.pickle</span>        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading index from                                                 \u001b]8;id=941171;file:///dhc/home/ignacio.rodriguez/xmen/xmen/linkers/faiss_indexer.py\u001b\\\u001b[2mfaiss_indexer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=625364;file:///dhc/home/ignacio.rodriguez/xmen/xmen/linkers/faiss_indexer.py#64\u001b\\\u001b[2m64\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         ..\u001b[35m/temp/icd10gm_index/index/sapbert/\u001b[0m\u001b[95membed_faiss_hier.pickle\u001b[0m        \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded index of type <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'faiss.swigfaiss_avx2.IndexHNSWFlat'</span><span style=\"font-weight: bold\">&gt;</span>  <a href=\"file:///dhc/home/ignacio.rodriguez/xmen/xmen/linkers/faiss_indexer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">faiss_indexer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///dhc/home/ignacio.rodriguez/xmen/xmen/linkers/faiss_indexer.py#66\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">66</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         and size <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15930</span>                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded index of type \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'faiss.swigfaiss_avx2.IndexHNSWFlat'\u001b[0m\u001b[1m>\u001b[0m  \u001b]8;id=667170;file:///dhc/home/ignacio.rodriguez/xmen/xmen/linkers/faiss_indexer.py\u001b\\\u001b[2mfaiss_indexer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=230267;file:///dhc/home/ignacio.rodriguez/xmen/xmen/linkers/faiss_indexer.py#66\u001b\\\u001b[2m66\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         and size \u001b[1;36m15930\u001b[0m                                                     \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_model_name = 'cambridgeltl/SapBERT-UMLS-2020AB-all-lang-from-XLMR'\n",
    "\n",
    "SapBERTLinker.clear()\n",
    "sapbert_linker = SapBERTLinker(\n",
    "    embedding_model_name = embedding_model_name,\n",
    "    index_base_path = f\"{base_path}/{label2dict[label]}_index/index/sapbert\",\n",
    "    k = 1000\n",
    ")\n",
    "\n",
    "pred_sapbert = sapbert_linker.predict_batch(ds, batch_size=128)\n",
    "\n",
    "# Save locally to avoid running it every time\n",
    "pred_sapbert.save_to_disk(f\"{base_path}/{label2dict[label]}_index/pred_sapbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbf542b1-60e7-4cb6-810f-956935037be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf@1 0.22677925211097708\n",
      "Perf@2 0.30639324487334135\n",
      "Perf@4 0.353437876960193\n",
      "Perf@8 0.4209891435464415\n",
      "Perf@16 0.4969843184559711\n",
      "Perf@32 0.5379975874547648\n",
      "Perf@64 0.6079613992762364\n"
     ]
    }
   ],
   "source": [
    "candidates = datasets.load_from_disk(f\"{base_path}/{label2dict[label]}_index/pred_sapbert\")\n",
    "\n",
    "# Recall for different numbers of candidates (k)\n",
    "_ = evaluate_at_k(ds['k5'], candidates['k5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7840718b-0581-4267-a809-fe4af2d71bc6",
   "metadata": {},
   "source": [
    "# Train Cross-encoder\n",
    "We use a cross-encoder to embed the mention with their context together with all potential candidates. This way, we can learn the best ranking of candidates from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "575c872c-9bf7-42a2-aaff-3fa67551a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.reranking.cross_encoder import CrossEncoderReranker, CrossEncoderTrainingArgs\n",
    "from xmen.linkers.util import filter_and_apply_threshold\n",
    "from xmen.kb import load_kb\n",
    "from xmen.data.indexed_dataset import IndexedDatasetDict, IndexedDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa5022-c5fd-4fc0-9fd2-5d00acbb987e",
   "metadata": {},
   "source": [
    "<u>This cell can be run just once. For subsequent runs you can load the result with the cell below this one.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32719dc5-35a4-48f9-82f7-d80cab1a4c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context length: 128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947ac6d01c784385bc39572e44f20660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/847 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd1f41944c5463182a329498da4b8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/847 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1d55ed64fa427aa31a4eb8b1eeca31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/847 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c750a3772ad34a5d89089ce36734c95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/771 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa513dafa6884471bb87f5d9afea58a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/771 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4954ec3d07054922b056bc2f5c46bf83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/771 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67354442eaa49e2990b0f731c52510d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/839 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc1ed938be14e9d9a9bd6413bb1e916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/839 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84735fda609d43a3805d58c74904fe5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/839 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44b9a739b0c4ba4834f1148c52d9155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/793 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15e50c261b2427fb4903a590530fe9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/793 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88e363a815f48478a83bb847df94a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/793 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c8955bdbd5449fbe952529b18504a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166d3dfe0af241f1af9e36e5c1713b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe2288374fe4ef8b87fc3a2239832ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'k1': [847 items],\n",
       " 'k2': [771 items],\n",
       " 'k3': [839 items],\n",
       " 'k4': [793 items],\n",
       " 'k5': [830 items]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_RERANKING = 64\n",
    "candidates = filter_and_apply_threshold(candidates, K_RERANKING, 0.0)\n",
    "kb = load_kb(f\"{base_path}/{label2dict[label]}.jsonl\")\n",
    "\n",
    "cross_enc_ds = CrossEncoderReranker.prepare_data(candidates, ds, kb)\n",
    "\n",
    "# Save locally to avoid running it every time\n",
    "cross_enc_ds.save_to_disk(f\"{base_path}/{label2dict[label]}_index/cross_encoded_dataset\")\n",
    "cross_enc_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "068368bd-6e02-4949-af9d-0a56b19ad818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k4': [793 items],\n",
       " 'k3': [839 items],\n",
       " 'k1': [847 items],\n",
       " 'k2': [771 items],\n",
       " 'k5': [830 items]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_enc_ds = IndexedDatasetDict.load_from_disk(f\"{base_path}/{label2dict[label]}_index/cross_encoded_dataset\")\n",
    "cross_enc_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae0c0c-da20-44fd-bed3-10afb8822049",
   "metadata": {},
   "source": [
    "Now we set the training arguments, train-eval splits and fit the model. Depending on the number of epochs, the training can take several hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e48b807-1758-4b02-9b97-f16cba80be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROSS_ENC_MODEL = \"SCAI-BIO/bio-gottbert-base\"#'cross-encoder/msmarco-MiniLM-L6-en-de-v1'\n",
    "NUM_EPOCHS = 5\n",
    "train_args = CrossEncoderTrainingArgs(\n",
    "    CROSS_ENC_MODEL, \n",
    "    NUM_EPOCHS,\n",
    "    score_regularization=True,\n",
    ")\n",
    "\n",
    "rr = CrossEncoderReranker()\n",
    "output_dir = f'{base_path}/{label2dict[label]}_index/cross_encoder_training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f959029-0cf1-4e8a-a11d-1f245c5b1347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name := SCAI-BIO/bio-gottbert-base\n",
      "num_train_epochs := 5\n",
      "fp16 := True\n",
      "label_smoothing := False\n",
      "score_regularization := True\n",
      "train_layers := None\n",
      "softmax_loss := True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SCAI-BIO/bio-gottbert-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SCAI-BIO/bio-gottbert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using score regularization: True\n",
      "Using label smoothing factor: False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8244df5fc3a4091b61ed0ed0e406a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bf73df1c63419197c99750bbf22afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 18:01:54 - EntityLinkingEvaluator: Evaluating the model on eval dataset after epoch 0:\n",
      "2023-05-30 18:02:32 - Accuracy: 0.39722572509457754\n",
      "2023-05-30 18:02:32 - Accuracy @ 5: 0.5145018915510718\n",
      "2023-05-30 18:02:32 - Accuracy @ 64: 0.5775535939470365\n",
      "2023-05-30 18:02:32 - Baseline Accuracy: 0.20933165195460277\n",
      "2023-05-30 18:02:32 - Save model to ../temp/icd10gm_index/cross_encoder_training/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75104cc681f14723b92b505e77d35a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 18:07:04 - EntityLinkingEvaluator: Evaluating the model on eval dataset after epoch 1:\n",
      "2023-05-30 18:07:42 - Accuracy: 0.4489281210592686\n",
      "2023-05-30 18:07:42 - Accuracy @ 5: 0.5397225725094578\n",
      "2023-05-30 18:07:42 - Accuracy @ 64: 0.5775535939470365\n",
      "2023-05-30 18:07:42 - Baseline Accuracy: 0.20933165195460277\n",
      "2023-05-30 18:07:42 - Save model to ../temp/icd10gm_index/cross_encoder_training/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea502f65a83143759495a1de30ab6b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 18:12:14 - EntityLinkingEvaluator: Evaluating the model on eval dataset after epoch 2:\n",
      "2023-05-30 18:12:52 - Accuracy: 0.47414880201765447\n",
      "2023-05-30 18:12:52 - Accuracy @ 5: 0.544766708701135\n",
      "2023-05-30 18:12:52 - Accuracy @ 64: 0.5775535939470365\n",
      "2023-05-30 18:12:52 - Baseline Accuracy: 0.20933165195460277\n",
      "2023-05-30 18:12:52 - Save model to ../temp/icd10gm_index/cross_encoder_training/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e87e93a14e94e37856b01f4da3a4a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 18:17:23 - EntityLinkingEvaluator: Evaluating the model on eval dataset after epoch 3:\n",
      "2023-05-30 18:18:02 - Accuracy: 0.5006305170239597\n",
      "2023-05-30 18:18:02 - Accuracy @ 5: 0.5573770491803278\n",
      "2023-05-30 18:18:02 - Accuracy @ 64: 0.5775535939470365\n",
      "2023-05-30 18:18:02 - Baseline Accuracy: 0.20933165195460277\n",
      "2023-05-30 18:18:02 - Save model to ../temp/icd10gm_index/cross_encoder_training/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70133442ee68479fb9668bb6c7dca298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 18:22:33 - EntityLinkingEvaluator: Evaluating the model on eval dataset after epoch 4:\n",
      "2023-05-30 18:23:11 - Accuracy: 0.5094577553593947\n",
      "2023-05-30 18:23:11 - Accuracy @ 5: 0.5561160151324086\n",
      "2023-05-30 18:23:11 - Accuracy @ 64: 0.5775535939470365\n",
      "2023-05-30 18:23:11 - Baseline Accuracy: 0.20933165195460277\n",
      "2023-05-30 18:23:11 - Save model to ../temp/icd10gm_index/cross_encoder_training/\n"
     ]
    }
   ],
   "source": [
    "# Choose train and evaluation folds\n",
    "train_folds = [\n",
    "    \"k1\",\n",
    "    \"k2\",\n",
    "    \"k3\",\n",
    "    \"k4\",\n",
    "    #\"k5\",\n",
    "]\n",
    "\n",
    "val_folds = [\n",
    "    #\"k1\",\n",
    "    #\"k2\",\n",
    "    #\"k3\",\n",
    "    \"k4\",\n",
    "    #\"k5\",\n",
    "] \n",
    "\n",
    "train, val = [], []\n",
    "train = sum([train + cross_enc_ds[k].dataset for k in train_folds],[])\n",
    "val = sum([val + cross_enc_ds[k].dataset for k in val_folds],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319a6fb-d34e-4df7-a322-c8f179424e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.fit(train, val, output_dir=output_dir, training_args=train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e84b2ad-4e5c-4af0-be37-3e29a4cc1a6f",
   "metadata": {},
   "source": [
    "# Evaluate Cross-encoder\n",
    "Now we can take our trained model and test it on data outside of training. Using the `xmen.evaluation` module, we gain insights into different error types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "056b9c8d-f364-420f-8d54-b3986f8b567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 18:34:17 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "rr = CrossEncoderReranker.load(output_dir, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9f97c16-f19c-4e54-9b4d-108a3c8f83c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3fb771a8ac422ba640f035a87d3b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc30bf79bde4c27bf70ab5409e7345d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "(1000, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m test_fold \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m cross_enc_pred_valid \u001b[38;5;241m=\u001b[39m \u001b[43mrr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrerank_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_fold\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_enc_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_fold\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m _ \u001b[38;5;241m=\u001b[39m evaluate_at_k(candidates[test_fold], cross_enc_pred_valid)\n",
      "File \u001b[0;32m~/xmen/xmen/reranking/cross_encoder.py:391\u001b[0m, in \u001b[0;36mCrossEncoderReranker.rerank_batch\u001b[0;34m(self, candidates, cross_enc_dataset, show_progress_bar, convert_to_numpy)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03mRe-ranks a batch of candidates using a cross encoder and returns the re-ranked candidates.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m- A dataset of re-ranked candidates.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    390\u001b[0m predictions \u001b[38;5;241m=\u001b[39m _cross_encoder_predict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, cross_enc_dataset\u001b[38;5;241m.\u001b[39mdataset, show_progress_bar, convert_to_numpy)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcandidates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_enc_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda3/envs/xmen/lib/python3.8/site-packages/datasets/arrow_dataset.py:563\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 563\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/conda3/envs/xmen/lib/python3.8/site-packages/datasets/arrow_dataset.py:528\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    526\u001b[0m }\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    530\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/conda3/envs/xmen/lib/python3.8/site-packages/datasets/arrow_dataset.py:3004\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2997\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[1;32m   2998\u001b[0m         disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   2999\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3002\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3003\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3004\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3005\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3006\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/conda3/envs/xmen/lib/python3.8/site-packages/datasets/arrow_dataset.py:3358\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3356\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3357\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3358\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[1;32m   3360\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/conda3/envs/xmen/lib/python3.8/site-packages/datasets/arrow_dataset.py:3261\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3260\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3261\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3263\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3264\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3265\u001b[0m     }\n",
      "File \u001b[0;32m~/xmen/xmen/reranking/cross_encoder.py:392\u001b[0m, in \u001b[0;36mCrossEncoderReranker.rerank_batch.<locals>.<lambda>\u001b[0;34m(d, i)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03mRe-ranks a batch of candidates using a cross encoder and returns the re-ranked candidates.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m- A dataset of re-ranked candidates.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    390\u001b[0m predictions \u001b[38;5;241m=\u001b[39m _cross_encoder_predict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, cross_enc_dataset\u001b[38;5;241m.\u001b[39mdataset, show_progress_bar, convert_to_numpy)\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m candidates\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m--> 392\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m d, i: \u001b[43mrerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_enc_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    393\u001b[0m     with_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    394\u001b[0m     load_from_cache_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    395\u001b[0m )\n",
      "File \u001b[0;32m~/xmen/xmen/reranking/cross_encoder.py:177\u001b[0m, in \u001b[0;36mrerank\u001b[0;34m(doc, index, doc_idx, ranking, reject_nil)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     rank \u001b[38;5;241m=\u001b[39m ranking[ranking_idx]\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(e[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(rank), (\u001b[38;5;28mlen\u001b[39m(e[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;28mlen\u001b[39m(rank))\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(e[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized\u001b[39m\u001b[38;5;124m\"\u001b[39m], rank):\n\u001b[1;32m    179\u001b[0m         n[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m r\n",
      "\u001b[0;31mAssertionError\u001b[0m: (1000, 64)"
     ]
    }
   ],
   "source": [
    "test_fold = \"k5\"\n",
    "\n",
    "cross_enc_pred_valid = rr.rerank_batch(candidates[test_fold], cross_enc_ds[test_fold])\n",
    "_ = evaluate_at_k(candidates[test_fold], cross_enc_pred_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee678d6e-4259-4eb9-bccb-f79355c705d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_util import analyze\n",
    "from xmen.evaluation import entity_linking_error_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950638c-032c-40a5-b37d-faf79e79fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_kb = load_kb(f\"{base_path}/{label2dict[label]}.jsonl\")\n",
    "error_cand = entity_linking_error_analysis(ds[test_fold], candidates[test_fold])\n",
    "edf_cand, _ = analyze(error_cand, cg_kb, 'eval', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e5d1f-ba9b-4eaf-8cfc-068ad83468c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False negative (not part of top 64)\n",
    "fns_cand = edf_cand[edf_cand.pred_index == -1]\n",
    "fns_cand_counts = fns_cand.error_type.value_counts() / len(edf_cand)\n",
    "fns_cand_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2faa75c-1835-41e4-848c-9bc340523018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking errors during candidate generation\n",
    "misranked_cand = edf_cand[edf_cand.pred_index > 0]\n",
    "misranked_cand_counts = misranked_cand.error_type.value_counts() / len(edf_cand)\n",
    "misranked_cand_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7948e53-e8c5-49ab-b4f9-98e22d386fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking errors after reranking\n",
    "error_rr = entity_linking_error_analysis(ds['validation'], cross_enc_pred_valid)\n",
    "edf_rr, _ = analyze(error_rr, cg_kb, 'eval', None)\n",
    "\n",
    "misranked_rr = edf_rr[edf_rr.pred_index > 0]\n",
    "misranked_rr_counts = misranked_rr.error_type.value_counts() / len(edf_rr)\n",
    "misranked_rr_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792329ac-251a-405e-a701-11400dc5b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Recall@1', (edf_rr.pred_index == 0).sum() / len(edf_rr))\n",
    "print('Recall@64', (edf_rr.pred_index >= 0).sum() / len(edf_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4442e571-9d17-4bf9-8d40-daee77e707a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "error_types = ['Complex Entity', 'Abbreviation', 'Wrong Type', 'Homonyms', 'Other Error']\n",
    "keys = ['COMPLEX_ENTITY', 'ABBREV', 'WRONG_SEMANTIC_TYPE', 'SAME_SYNONYMS', 'UNKNOWN_ERROR']\n",
    "counts = [fns_cand_counts, misranked_cand_counts, misranked_rr_counts]\n",
    "count_names = ['False Negatives', 'Candidate Generation Errors', 'Reranking Errors']\n",
    "\n",
    "hatches = ['', '\\\\\\\\\\\\', '///']\n",
    "colors = ['lightyellow', '#C0F5EC', '#118470']\n",
    "\n",
    "matplotlib.rcParams['hatch.linewidth'] = 0.3 \n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "\n",
    "fig, axs = plt.subplots(1, len(keys), figsize=(8, 2))\n",
    "for i, (key, error) in enumerate(zip(keys, error_types)):\n",
    "    for j, bar in enumerate(axs[i].bar(x=count_names, height=[c.get(key, 0.0) for c in counts], color=colors, edgecolor = 'black', linewidth=0.2)):\n",
    "        bar.set_hatch(hatches[j])\n",
    "    axs[i].grid(axis='y')\n",
    "    axs[i].set_ylim([0.0, 0.2])\n",
    "    axs[i].set_xlabel(error, labelpad=10)\n",
    "    axs[i].get_xaxis().set_ticks([])\n",
    "handles = [plt.Rectangle((0,0),1,1, facecolor=color, linewidth=0.2, edgecolor='black', hatch=h) for color, h in zip(colors, hatches)]\n",
    "plt.legend(handles, count_names, loc='upper center', bbox_to_anchor=(-3.1, 1.4, 0, 0), ncol=len(counts))\n",
    "\n",
    "plt.subplots_adjust(wspace=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xmen",
   "language": "python",
   "name": "xmen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
