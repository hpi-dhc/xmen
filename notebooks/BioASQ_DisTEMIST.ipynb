{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Linking Pipeline for [DisTEMIST](https://temu.bsc.es/distemist/) Shared Task (10th BioASQ Workshop)\n",
    "\n",
    "The goal is to link disease mentions in Spanish case reports to SNOMED CT IDs.\n",
    "\n",
    "Highlights:\n",
    "- Building a custom dictionary based on the (non-UMLS) DisTEMIST gazetteer + multilingual UMLS synonyms\n",
    "- Using an Ensemble of TFIDFNgramLinker + SapBERTLinker\n",
    "- Reranking with a trainable CrossEncoderReranker\n",
    "- Evaluation and Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.evaluation import entity_linking_error_analysis, evaluate_at_k\n",
    "from xmen.linkers.util import filter_and_apply_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: adapt `umls_meta_path` in `../conf/distemist.yaml` to point to the location of your UMLS release (you might want to set the environment variable `$UMLS_HOME`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.confhelper import load_config\n",
    "config = load_config('../conf/distemist.yaml')\n",
    "base_path = Path(config.cache_dir)\n",
    "tmp_path = Path('..') / 'temp' / 'distemist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/Florian.Borchert/.cache/huggingface/modules/datasets_modules/datasets/distemist/f63b2c6775932c342d7bff59d751d6139c0c52c5255f7fbb3e458d255728a8dd (last modified on Thu Apr 20 13:14:35 2023) since it couldn't be found locally at distemist., or remotely on the Hugging Face Hub.\n",
      "Found cached dataset distemist (/home/Florian.Borchert/.cache/huggingface/datasets/distemist/distemist_linking_bigbio_kb/1.0.0/f63b2c6775932c342d7bff59d751d6139c0c52c5255f7fbb3e458d255728a8dd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f01e3564834879bee9bbbe84f31273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/Florian.Borchert/.cache/huggingface/datasets/distemist/distemist_linking_bigbio_kb/1.0.0/f63b2c6775932c342d7bff59d751d6139c0c52c5255f7fbb3e458d255728a8dd/cache-39869da4ad369074.arrow\n",
      "Loading cached processed dataset at /home/Florian.Borchert/.cache/huggingface/datasets/distemist/distemist_linking_bigbio_kb/1.0.0/f63b2c6775932c342d7bff59d751d6139c0c52c5255f7fbb3e458d255728a8dd/cache-955d26b050eff51d.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations'],\n",
       "        num_rows: 466\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations'],\n",
       "        num_rows: 117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "ds = datasets.load_dataset('distemist', 'distemist_linking_bigbio_kb')\n",
    "\n",
    "# Own validation set (20% of distemist training set / EL sub-track)\n",
    "with open('distemist_validation_docs.txt', 'r') as fh:\n",
    "    valid_ids = [l.strip() for l in fh.readlines()]\n",
    "    \n",
    "ds_train = ds['train'].filter(lambda d: d['document_id'] not in valid_ids)\n",
    "ds_valid = ds['train'].filter(lambda d: d['document_id'] in valid_ids)\n",
    "\n",
    "ds['train'] = ds_train\n",
    "ds['validation'] = ds_valid\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preparation - Just run once\n",
    "\n",
    "__Note__: This is a bit more involved, because we dynamically explore different combinations of DisTEMIST gazetteer and UMLS subsets.\n",
    "\n",
    "In most normal cases, you just want to configure the target dictionary in your .yaml file and run `xmen dict` and `xmen index` with default settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Distemist gazetteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-26 21:47:53--  https://zenodo.org/record/6505583/files/dictionary_distemist.tsv?download=0\n",
      "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
      "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9885605 (9.4M) [application/octet-stream]\n",
      "Saving to: ‘../temp/dictionary_distemist.tsv’\n",
      "\n",
      "../temp/dictionary_ 100%[===================>]   9.43M  7.32MB/s    in 1.3s    \n",
      "\n",
      "2023-05-26 21:47:56 (7.32 MB/s) - ‘../temp/dictionary_distemist.tsv’ saved [9885605/9885605]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ../temp; wget https://zenodo.org/record/6505583/files/dictionary_distemist.tsv?download=0 -O ../temp/dictionary_distemist.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the DisTEMIST Task only covers a subset of SNOMED CT codes, we retrieve only additional synonyms for the UMLS for these codes.\n",
    "Thus, we need to map CUIs to SNOMED CT IDs and merge them with the DisTEMIST gazetteer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_configs = ['distemist_gazetteer', 'distemist_umls_es', 'distemist_umls_en_es', 'distemist_umls_all'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`xmen dict conf/distemist.yaml --code dicts/distemist.py --key distemist_gazetteer`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`xmen dict conf/distemist.yaml --code dicts/distemist.py --key distemist_umls_es`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`xmen dict conf/distemist.yaml --code dicts/distemist.py --key distemist_umls_en_es`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`xmen dict conf/distemist.yaml --code dicts/distemist.py --key distemist_umls_all`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Run these commands from the root folder\n",
    "for d in dict_configs:\n",
    "    display(Markdown(f\"`xmen dict conf/distemist.yaml --code dicts/distemist.py --key {d}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = Path(config.umls_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from xmen.umls import read_umls_file_headers\n",
    "\n",
    "def read_cui2snomed_mapping(meta_path):\n",
    "    mrconso = 'MRCONSO.RRF'\n",
    "    cui2snomed = defaultdict(list)\n",
    "    headers = read_umls_file_headers(meta_path, mrconso)\n",
    "    with open(f\"{meta_path}/{mrconso}\") as fin:\n",
    "        for line in tqdm(fin.readlines()):\n",
    "            splits = line.strip().split(\"|\")\n",
    "            assert len(headers) == len(splits)\n",
    "            concept = dict(zip(headers, splits))\n",
    "            if concept['SAB'] in ['SNOMEDCT_US', 'SCTSPA']:\n",
    "                cui2snomed[concept['CUI']].append(concept['SCUI'])\n",
    "    return cui2snomed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bc0ed5678e435aad17e3292edd4459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16857345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cui2snomed_mapping = read_cui2snomed_mapping(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from xmen.kb import CompositeKnowledgebase\n",
    "\n",
    "def cui2snomed(entry):\n",
    "    res = []\n",
    "    cui = entry['concept_id']\n",
    "    for sctid in cui2snomed_mapping[cui]:\n",
    "        r = entry.copy()\n",
    "        r['concept_id'] = sctid\n",
    "        res.append(r)\n",
    "    return res\n",
    "\n",
    "def merge_and_write_dicts(target_jsonl, added_jsonl, output_jsonl):\n",
    "    print(f'Writing to {output_jsonl}')\n",
    "    output_jsonl.parent.mkdir(exist_ok=True, parents=True)\n",
    "    cui_count = alias_count = 0\n",
    "    kb = CompositeKnowledgebase([added_jsonl], mappers=[cui2snomed])\n",
    "    with open(output_jsonl, 'w') as fo:\n",
    "        for l in tqdm(list(open(target_jsonl).readlines())):\n",
    "            cui_count += 1\n",
    "            entry = json.loads(l)\n",
    "            sctid = str(entry['concept_id'])\n",
    "            if sctid in kb.cui_to_entity:\n",
    "                concept = kb.cui_to_entity[sctid]\n",
    "                known_aliases = [entry['canonical_name']] + entry['aliases']\n",
    "                new_aliases = [c for c in [concept.canonical_name] + concept.aliases if c not in known_aliases]\n",
    "            else:\n",
    "                new_aliases = []\n",
    "            entry['aliases'] += new_aliases\n",
    "            alias_count += (len(entry['aliases']) + 1)\n",
    "            fo.write(json.dumps(entry) + '\\n')\n",
    "    print(f'Written {cui_count} concepts with {alias_count} aliases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "distemist_gazetteer_jsonl = base_path / 'distemist_gazetteer' / 'distemist_gazetteer.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/Florian.Borchert/.cache/xmen/distemist/merged/distemist_umls_es.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d486028d52846bbbeec47e7aa49c331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 111179 concepts with 495324 aliases\n",
      "Writing to /home/Florian.Borchert/.cache/xmen/distemist/merged/distemist_umls_en_es.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48137530a7a64b6ba1b0a1e06bb0f34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 111179 concepts with 1520890 aliases\n",
      "Writing to /home/Florian.Borchert/.cache/xmen/distemist/merged/distemist_umls_all.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f38af822e547fbb7d3d19e5dcd78b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 111179 concepts with 2482643 aliases\n"
     ]
    }
   ],
   "source": [
    "for d in dict_configs[1:]:\n",
    "    merge_and_write_dicts(distemist_gazetteer_jsonl, base_path / d / f'{d}.jsonl', base_path / 'distemist' / 'merged' / f'{d}.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare TF-IDF NGram and SapBERT indices for all configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`xmen index conf/distemist.yaml --dict /home/Florian.Borchert/.cache/xmen/distemist_gazetteer/distemist_gazetteer.jsonl --output /home/Florian.Borchert/.cache/xmen/distemist/merged/distemist_gazetteer --all`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`xmen index conf/distemist.yaml --dict /home/Florian.Borchert/.cache/xmen/distemist/merged/distemist_umls_es.jsonl --output /home/Florian.Borchert/.cache/xmen/distemist/merged/distemist_umls_es --all`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`xmen index conf/distemist.yaml --dict /home/Florian.Borchert/.cache/xmen/distemist/merged/distemist_umls_en_es.jsonl --output /home/Florian.Borchert/.cache/xmen/distemist/merged/distemist_umls_en_es --all`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`xmen index conf/distemist.yaml --dict /home/Florian.Borchert/.cache/xmen/distemist/merged/distemist_umls_all.jsonl --output /home/Florian.Borchert/.cache/xmen/distemist/merged/distemist_umls_all --all`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run these commands from the root folder\n",
    "display(Markdown(f\"`xmen index conf/distemist.yaml --dict {base_path / 'distemist_gazetteer' / 'distemist_gazetteer.jsonl'} --output {base_path / 'distemist' / 'merged' / 'distemist_gazetteer'} --all`\"))\n",
    "for d in dict_configs[1:]:\n",
    "    display(Markdown(f\"`xmen index conf/distemist.yaml --dict {base_path / 'distemist' / 'merged' / f'{d}.jsonl'} --output {base_path / 'distemist' / 'merged' / f'{d}'} --all`\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Candidate Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We configure two candidate generators:\n",
    "1. `TFIDFNGramLinker`, which links surface forms based on TF-IDF scores over character ngrams\n",
    "2. `SapBERTLinker`, which uses a Transformer model to retrieve candidates with dense embeddings\n",
    "\n",
    "Finally, we combine their predictions using an `EnsembleLinker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_config = 'distemist_umls_en_es'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.linkers import TFIDFNGramLinker, SapBERTLinker, EnsembleLinker\n",
    "from xmen.linkers.util import filter_and_apply_threshold\n",
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_base_path = base_path / 'distemist' / 'merged' / dict_config / 'index'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF over character n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_linker = TFIDFNGramLinker(index_base_path=index_base_path / 'ngrams', k=100)\n",
    "pred_ngram = ngram_linker.predict_batch(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall for different numbers of candidates (k)\n",
    "_ = evaluate_at_k(ds['validation'], pred_ngram['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense Retrieval with SapBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear singleton to free up memory\n",
    "SapBERTLinker.clear()\n",
    "sapbert_linker = SapBERTLinker(\n",
    "    index_base_path = index_base_path / 'sapbert',\n",
    "    k = 1000\n",
    ")\n",
    "\n",
    "pred_sapbert = sapbert_linker.predict_batch(ds, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall for different numbers of candidates (k)\n",
    "_ = evaluate_at_k(ds['validation'], pred_sapbert['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_linker = EnsembleLinker()\n",
    "ensemble_linker.add_linker('sapbert', sapbert_linker, k=100)\n",
    "ensemble_linker.add_linker('ngram', ngram_linker, k=100)\n",
    "\n",
    "# Re-use predictions for efficiency\n",
    "# TODO: reuse_preds currently does not work with dataset dicts\n",
    "pred_ensemble = DatasetDict()\n",
    "pred_ensemble['train'] = ensemble_linker.predict_batch(ds['train'], 128, 100, reuse_preds={'sapbert' : pred_sapbert['train'], 'ngram' : pred_ngram['train']})\n",
    "pred_ensemble['validation'] = ensemble_linker.predict_batch(ds['validation'], 128, 100, reuse_preds={'sapbert' : pred_sapbert['validation'], 'ngram' : pred_ngram['validation']})\n",
    "pred_ensemble['test'] = ensemble_linker.predict_batch(ds['test'], 128, 100, reuse_preds={'sapbert' : pred_sapbert['test'], 'ngram' : pred_ngram['test']})\n",
    "\n",
    "pred_ensemble.save_to_disk(tmp_path / dict_config / 'pred_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall for different numbers of candidates (k)\n",
    "_ = evaluate_at_k(ds['validation'], pred_ensemble['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking\n",
    "\n",
    "We use a cross-encoder to embed the mention with their context together with all potential candidates. This way, we can learn the best ranking of candidates from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.reranking.cross_encoder import CrossEncoderReranker, CrossEncoderTrainingArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_RERANKING = 64\n",
    "CROSS_ENC_MODEL = 'PlanTL-GOB-ES/roberta-base-biomedical-clinical-es'\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Cross-Encoder Training\n",
    "Create a dataset of samples for each instance with all potential candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary used for synonyms in entity representation. \n",
    "# Note: You may or may not use the config used for candidate generation here. We used a different one, to demonstrate the available options.\n",
    "dict_config_rr = 'distemist_umls_es'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the ensemble predictions as candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.linkers.util import filter_and_apply_threshold\n",
    "\n",
    "candidates = datasets.load_from_disk(tmp_path / dict_config / 'pred_ensemble')\n",
    "candidates = filter_and_apply_threshold(candidates, K_RERANKING, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a knowledgebase to retrieve the synonyms per concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.kb import load_kb\n",
    "kb = load_kb(base_path / 'distemist' / 'merged' / f'{dict_config_rr}.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_enc_ds = CrossEncoderReranker.prepare_data(candidates, ds, kb, encode_sem_type=True)\n",
    "cross_enc_ds.save_to_disk(tmp_path / f'cross_enc_ds_{dict_config_rr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Cross Encoder\n",
    "\n",
    "The cross-encoder is trained for 20 epochs, the final model is saved to `output_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.data.indexed_dataset import IndexedDatasetDict\n",
    "cross_enc_ds = IndexedDatasetDict.load_from_disk(tmp_path / f'cross_enc_ds_{dict_config_rr}')\n",
    "cross_enc_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_enc_ds['train'].dataset[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = CrossEncoderTrainingArgs(\n",
    "    CROSS_ENC_MODEL, \n",
    "    NUM_EPOCHS,\n",
    "    score_regularization=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = CrossEncoderReranker()\n",
    "output_dir = f'{tmp_path}/cross_encoder_training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on the number of epochs, this can take a few hours\n",
    "rr.fit(cross_enc_ds['train'].dataset, cross_enc_ds['validation'].dataset, output_dir=output_dir, training_args=train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test Set\n",
    "\n",
    "We load the final model to get predictions on the test set and run the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = CrossEncoderReranker.load(output_dir, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_enc_pred_valid = rr.rerank_batch(candidates['validation'], cross_enc_ds['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate_at_k(ds['validation'], cross_enc_pred_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_enc_pred = rr.rerank_batch(candidates['test'], cross_enc_ds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate_at_k(ds['test'], cross_enc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis\n",
    "\n",
    "Using the `xmen.evaluation` module, we gain insights into different error types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_util import analyze\n",
    "from xmen.kb import load_kb\n",
    "from xmen.evaluation import entity_linking_error_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_kb = load_kb(base_path / 'distemist' / 'merged' / f'{dict_config}.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_cand = entity_linking_error_analysis(ds['validation'], candidates['validation'])\n",
    "edf_cand, _ = analyze(error_cand, cg_kb, 'eval', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False negative (not part of top 64)\n",
    "fns_cand = edf_cand[edf_cand.pred_index == -1]\n",
    "fns_cand_counts = fns_cand.error_type.value_counts() / len(edf_cand)\n",
    "fns_cand_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking errors during candidate generation\n",
    "misranked_cand = edf_cand[edf_cand.pred_index > 0]\n",
    "misranked_cand_counts = misranked_cand.error_type.value_counts() / len(edf_cand)\n",
    "misranked_cand_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking errors after reranking\n",
    "error_rr = entity_linking_error_analysis(ds['validation'], cross_enc_pred_valid)\n",
    "edf_rr, _ = analyze(error_rr, cg_kb, 'eval', None)\n",
    "\n",
    "misranked_rr = edf_rr[edf_rr.pred_index > 0]\n",
    "misranked_rr_counts = misranked_rr.error_type.value_counts() / len(edf_rr)\n",
    "misranked_rr_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Recall@1', (edf_rr.pred_index == 0).sum() / len(edf_rr))\n",
    "print('Recall@64', (edf_rr.pred_index >= 0).sum() / len(edf_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "error_types = ['Complex Entity', 'Abbreviation', 'Wrong Type', 'Homonyms', 'Other Error']\n",
    "keys = ['COMPLEX_ENTITY', 'ABBREV', 'WRONG_SEMANTIC_TYPE', 'SAME_SYNONYMS', 'UNKNOWN_ERROR']\n",
    "counts = [fns_cand_counts, misranked_cand_counts, misranked_rr_counts]\n",
    "count_names = ['False Negatives', 'Candidate Generation Errors', 'Reranking Errors']\n",
    "\n",
    "hatches = ['', '\\\\\\\\\\\\', '///']\n",
    "colors = ['lightyellow', '#C0F5EC', '#118470']\n",
    "\n",
    "matplotlib.rcParams['hatch.linewidth'] = 0.3 \n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "\n",
    "fig, axs = plt.subplots(1, len(keys), figsize=(8, 2))\n",
    "for i, (key, error) in enumerate(zip(keys, error_types)):\n",
    "    for j, bar in enumerate(axs[i].bar(x=count_names, height=[c.get(key, 0.0) for c in counts], color=colors, edgecolor = 'black', linewidth=0.2)):\n",
    "        bar.set_hatch(hatches[j])\n",
    "    axs[i].grid(axis='y')\n",
    "    axs[i].set_ylim([0.0, 0.2])\n",
    "    axs[i].set_xlabel(error, labelpad=10)\n",
    "    axs[i].get_xaxis().set_ticks([])\n",
    "handles = [plt.Rectangle((0,0),1,1, facecolor=color, linewidth=0.2, edgecolor='black', hatch=h) for color, h in zip(colors, hatches)]\n",
    "plt.legend(handles, count_names, loc='upper center', bbox_to_anchor=(-3.1, 1.4, 0, 0), ncol=len(counts))\n",
    "\n",
    "plt.subplots_adjust(wspace=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xmen_notebooks]",
   "language": "python",
   "name": "conda-env-xmen_notebooks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
